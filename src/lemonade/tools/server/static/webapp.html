<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lemonade Server</title>
    <link rel="icon" href="/static/favicon.ico">
    <link rel="stylesheet" href="/static/styles.css">
    <script>
    window.SERVER_PORT = {{SERVER_PORT}};
    </script>
    {{SERVER_MODELS_JS}}
</head>
<body>
    <nav class="navbar">
        <a href="https://github.com/lemonade-sdk/lemonade" target="_blank">GitHub</a>
        <a href="https://lemonade-server.ai/docs/" target="_blank">Docs</a>
        <a href="https://lemonade-server.ai/docs/server/server_models/" target="_blank">Models</a>
        <a href="https://lemonade-server.ai/docs/server/apps/" target="_blank">Featured Apps</a>
    </nav>
    <main class="main">
        <div class="title">üçã Lemonade Server</div>
        <div class="tab-container"> 
            <div class="tabs"> 
                <button class="tab active" id="tab-chat" onclick="showTab('chat')">LLM Chat</button> 
                <button class="tab" id="tab-models" onclick="showTab('models')">Model Management</button> 
            </div> 
            <div class="tab-content active" id="content-chat"> 
                <div class="chat-container"> 
                    <div class="chat-history" id="chat-history"></div> 
                    <div class="chat-input-row"> 
                        <select id="model-select"></select> 
                        <input type="text" id="chat-input" placeholder="Type your message..." /> 
                        <button id="send-btn">Send</button> 
                    </div> 
                </div> 
            </div> 
            <div class="tab-content" id="content-models">                <div class="model-mgmt-register-form collapsed">                    <h3 class="model-mgmt-form-title" onclick="toggleAddModelForm()">
                        Add a Model
                        <span class="tooltip-icon" data-tooltip="Lemonade Server has a built-in set of suggested models, however you can use this form to add any compatible GGUF or ONNX model you like from Hugging Face.">‚ìò</span>
                    </h3>
                    <form id="register-model-form" autocomplete="off" class="form-content">
                        <div class="register-form-row">
                        <label class="register-label">
                            Model Name
                            <span class="tooltip-icon" data-tooltip="Enter a unique short name for your model. This is how the model will be referenced by Lemonade Server and connected apps. It will be prefixed with 'user.' to distinguish it from the built-in models.">‚ìò</span>
                        </label>
                        <div class="register-model-name-group">
                            <span class="register-model-prefix styled-prefix">user.</span>
                            <input type="text" id="register-model-name" name="model_name" placeholder="Gemma-3-12b-it-GGUF" required autocomplete="off">
                        </div>
                        </div>
                        <div class="register-form-row">
                        <label class="register-label">
                            Checkpoint
                            <span class="tooltip-icon" data-tooltip="Specify the model checkpoint path from Hugging Face (e.g., org-name/model-name:variant).">‚ìò</span>
                        </label>
                        <input type="text" id="register-checkpoint" name="checkpoint" placeholder="unsloth/gemma-3-12b-it-GGUF:Q4_0" class="register-textbox" autocomplete="off">
                        </div>
                        <div class="register-form-row">
                        <label class="register-label">
                            Recipe
                            <span class="tooltip-icon" data-tooltip="Select the Lemonade recipe corresponding to the inference engine and device Lemonade Server should use for the model. Use llamacpp for GGUF models. For OGA/ONNX models, click the More Info button to learn about the oga-* recipes.">‚ìò</span>
                        </label>
                        <select id="register-recipe" name="recipe" required>
                            <option value="llamacpp">llamacpp</option>
                            <option value="oga-hybrid">oga-hybrid</option>
                            <option value="oga-cpu">oga-cpu</option>
                        </select>
                        <a href="https://lemonade-server.ai/docs/lemonade_api/" target="_blank" class="register-doc-link">More info</a>
                        </div>
                        <div class="register-form-row register-form-row-tight">
                        <label class="register-label">
                            mmproj file
                            <span class="tooltip-icon" data-tooltip="Specify an mmproj file from the same Hugging Face checkpoint as the model. This is used for multimodal models, such as VLMs. Leave empty if not needed.">‚ìò</span>
                        </label>
                        <input type="text" id="register-mmproj" name="mmproj" placeholder="(Optional) mmproj-F16.gguf" autocomplete="off">
                        <label class="register-label reasoning-inline">
                            <input type="checkbox" id="register-reasoning" name="reasoning">
                            Reasoning
                            <span class="tooltip-icon" data-tooltip="Enable to inform Lemonade Server that the model has reasoning capabilities that will use thinking tokens.">‚ìò</span>
                        </label>
                        </div>
                        <div class="register-form-row register-form-row-tight">
                        <button type="submit" id="register-submit">Install</button>
                        <span id="register-model-status" class="register-status"></span>                        </div>
                    </form>
                </div>
                <div class="model-mgmt-container">
                    <div class="model-mgmt-pane">
                        <h3>Installed Models</h3>
                        <table class="model-table" id="installed-models-table">
                            <colgroup><col style="width:100%"></colgroup>
                            <tbody id="installed-models-tbody"></tbody>
                        </table>
                    </div>
                    <div class="model-mgmt-pane">
                        <h3>Suggested Models</h3>
                        <table class="model-table" id="suggested-models-table">
                            <tbody id="suggested-models-tbody"></tbody>
                        </table>
                    </div>
                </div>
            </div> 
        </div> 
    </main>
    <footer class="site-footer">
        <div class="dad-joke">When life gives you LLMs, make an LLM aide.</div>
        <div class="copyright">Copyright 2025 AMD</div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/openai@4.21.0/dist/openai.min.js"></script> 
    <script>    // Tab switching logic 
    function showTab(tab, updateHash = true) { 
        document.getElementById('tab-chat').classList.remove('active'); 
        document.getElementById('tab-models').classList.remove('active'); 
        document.getElementById('content-chat').classList.remove('active'); 
        document.getElementById('content-models').classList.remove('active'); 
        if (tab === 'chat') { 
            document.getElementById('tab-chat').classList.add('active'); 
            document.getElementById('content-chat').classList.add('active');
            if (updateHash) {
                window.location.hash = 'llm-chat';
            }
        } else { 
            document.getElementById('tab-models').classList.add('active'); 
            document.getElementById('content-models').classList.add('active');
            if (updateHash) {
                window.location.hash = 'model-management';
            }
        } 
    }

    // Handle hash changes for anchor navigation
    function handleHashChange() {
        const hash = window.location.hash.slice(1); // Remove the # symbol
        if (hash === 'llm-chat') {
            showTab('chat', false);
        } else if (hash === 'model-management') {
            showTab('models', false);
        }
    }

    // Initialize tab based on URL hash on page load
    function initializeTabFromHash() {
        const hash = window.location.hash.slice(1);
        if (hash === 'llm-chat') {
            showTab('chat', false);
        } else if (hash === 'model-management') {
            showTab('models', false);
        }
        // If no hash or unrecognized hash, keep default (chat tab is already active)
    }

    // Listen for hash changes
    window.addEventListener('hashchange', handleHashChange);

    // Initialize on page load
    document.addEventListener('DOMContentLoaded', initializeTabFromHash);

    // Toggle Add Model form
    function toggleAddModelForm() {
        const form = document.querySelector('.model-mgmt-register-form');
        form.classList.toggle('collapsed');
    }

    // Helper to get server base URL
    function getServerBaseUrl() {
        const port = window.SERVER_PORT || 8000;
        return `http://localhost:${port}`;
    }

    // Populate model dropdown from /api/v1/models endpoint
    async function loadModels() {
        try {
            const resp = await fetch(getServerBaseUrl() + '/api/v1/models');
            const data = await resp.json();
            const select = document.getElementById('model-select');
            select.innerHTML = '';
            if (!data.data || !Array.isArray(data.data)) {
                select.innerHTML = '<option>No models found (malformed response)</option>';
                return;
            }
            if (data.data.length === 0) {
                select.innerHTML = '<option>No models available</option>';
                return;
            }
            let defaultIndex = 0;
            data.data.forEach(function(model, index) {
                const modelId = model.id || model.name || model;
                const opt = document.createElement('option');
                opt.value = modelId;
                opt.textContent = modelId;
                if (modelId === 'Llama-3.2-1B-Instruct-Hybrid') {
                    defaultIndex = index;
                }
                select.appendChild(opt);
            });
            select.selectedIndex = defaultIndex;
        } catch (e) {
            const select = document.getElementById('model-select');
            select.innerHTML = `<option>Error loading models: ${e.message}</option>`;
            console.error('Error loading models:', e);
        }
    }
    loadModels();

    // Helper function to create model name with labels
    function createModelNameWithLabels(modelId, allModels) {
        // Create container for model name and labels
        const container = document.createElement('div');
        container.className = 'model-labels-container';
        
        // Add model name
        const nameSpan = document.createElement('span');
        nameSpan.textContent = modelId;
        container.appendChild(nameSpan);
        
        // Add labels if they exist
        const modelData = allModels[modelId];
        if (modelData) {
            // Add reasoning label if reasoning is true
            if (modelData.reasoning === true) {
                const reasoningLabel = document.createElement('span');
                reasoningLabel.className = 'model-label reasoning';
                reasoningLabel.textContent = 'reasoning';
                container.appendChild(reasoningLabel);
            }
            
            // Add other labels if they exist
            if (modelData.labels && Array.isArray(modelData.labels)) {
                modelData.labels.forEach(label => {
                    const labelSpan = document.createElement('span');
                    const labelLower = label.toLowerCase();
                    const labelClass = (labelLower === 'vision') ? 'vision' : 'other';
                    labelSpan.className = `model-label ${labelClass}`;
                    labelSpan.textContent = label;
                    container.appendChild(labelSpan);
                });
            }
        }
        
        return container;
    }

    // Model Management Tab Logic
    async function refreshModelMgmtUI() {
        // Get installed models from /api/v1/models
        let installed = [];
        try {
            const resp = await fetch(getServerBaseUrl() + '/api/v1/models');
            const data = await resp.json();
            if (data.data && Array.isArray(data.data)) {
                installed = data.data.map(m => m.id || m.name || m);
            }
        } catch (e) {}
        // All models from server_models.json (window.SERVER_MODELS)
        const allModels = window.SERVER_MODELS || {};
        // Filter suggested models not installed
        const suggested = Object.keys(allModels).filter(
            k => allModels[k].suggested && !installed.includes(k)
        );
        // Render installed models as a table (two columns, second is invisible)
        const installedTbody = document.getElementById('installed-models-tbody');
        installedTbody.innerHTML = '';
        installed.forEach(function(mid) {
            var tr = document.createElement('tr');
            var tdName = document.createElement('td');
            
            tdName.appendChild(createModelNameWithLabels(mid, allModels));
            tdName.style.paddingRight = '1em';
            tdName.style.verticalAlign = 'middle';
            
            var tdBtn = document.createElement('td');
            tdBtn.style.width = '1%';
            tdBtn.style.verticalAlign = 'middle';
            const btn = document.createElement('button');
            btn.textContent = '‚àí';
            btn.title = 'Delete model';
            btn.style.cursor = 'pointer';
            btn.onclick = async function() {
                if (!confirm(`Are you sure you want to delete the model "${mid}"?`)) {
                    return;
                }
                btn.disabled = true;
                btn.textContent = 'Deleting...';
                btn.style.backgroundColor = '#888';
                try {
                    const response = await fetch(getServerBaseUrl() + '/api/v1/delete', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ model_name: mid })
                    });
                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(errorData.detail || 'Failed to delete model');
                    }
                    await refreshModelMgmtUI();
                    await loadModels(); // update chat dropdown too
                } catch (e) {
                    btn.textContent = 'Error';
                    btn.disabled = false;
                    alert(`Failed to delete model: ${e.message}`);
                }
            };
            tdBtn.appendChild(btn);
            
            tr.appendChild(tdName);
            tr.appendChild(tdBtn);
            installedTbody.appendChild(tr);
        });
        // Render suggested models as a table
        const suggestedTbody = document.getElementById('suggested-models-tbody');
        suggestedTbody.innerHTML = '';
        suggested.forEach(mid => {
            const tr = document.createElement('tr');
            const tdName = document.createElement('td');
            
            tdName.appendChild(createModelNameWithLabels(mid, allModels));
            tdName.style.paddingRight = '1em';
            tdName.style.verticalAlign = 'middle';
            const tdBtn = document.createElement('td');
            tdBtn.style.width = '1%';
            tdBtn.style.verticalAlign = 'middle';
            const btn = document.createElement('button');
            btn.textContent = '+';
            btn.title = 'Install model';
            btn.onclick = async function() {
                btn.disabled = true;
                btn.textContent = 'Installing...';
                btn.classList.add('installing-btn');
                try {
                    await fetch(getServerBaseUrl() + '/api/v1/pull', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ model_name: mid })
                    });
                    await refreshModelMgmtUI();
                    await loadModels(); // update chat dropdown too
                } catch (e) {
                    btn.textContent = 'Error';
                }
            };
            tdBtn.appendChild(btn);
            tr.appendChild(tdName);
            tr.appendChild(tdBtn);
            suggestedTbody.appendChild(tr);
        });
    }
    // Initial load
    refreshModelMgmtUI();
    // Optionally, refresh when switching to the tab
    document.getElementById('tab-models').addEventListener('click', refreshModelMgmtUI);

    // Chat logic (streaming with OpenAI JS client placeholder)
    const chatHistory = document.getElementById('chat-history');
    const chatInput = document.getElementById('chat-input');
    const sendBtn = document.getElementById('send-btn');
    const modelSelect = document.getElementById('model-select');
    let messages = [];

    function appendMessage(role, text) {
        const div = document.createElement('div');
        div.className = 'chat-message ' + role;
        // Add a bubble for iMessage style
        const bubble = document.createElement('div');
        bubble.className = 'chat-bubble ' + role;
        bubble.innerHTML = text;
        div.appendChild(bubble);
        chatHistory.appendChild(div);
        chatHistory.scrollTop = chatHistory.scrollHeight;
    }

    async function sendMessage() {
        const text = chatInput.value.trim();
        if (!text) return;
        appendMessage('user', text);
        messages.push({ role: 'user', content: text });
        chatInput.value = '';
        sendBtn.disabled = true;
        // Streaming OpenAI completions (placeholder, adapt as needed)
        let llmText = '';
        appendMessage('llm', '...');
        const llmDiv = chatHistory.lastChild.querySelector('.chat-bubble.llm');
        try {
            // Use the correct endpoint for chat completions
            const resp = await fetch(getServerBaseUrl() + '/api/v1/chat/completions', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model: modelSelect.value,
                    messages: messages,
                    stream: true
                })
            });
            if (!resp.body) throw new Error('No stream');
            const reader = resp.body.getReader();
            let decoder = new TextDecoder();
            llmDiv.textContent = '';
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                const chunk = decoder.decode(value);
                if (chunk.trim() === 'data: [DONE]' || chunk.trim() === '[DONE]') continue;
                // Try to extract the content from the OpenAI chunk
                const match = chunk.match(/"content"\s*:\s*"([^"]*)"/);
                if (match && match[1]) {
                    llmText += match[1];
                    llmDiv.textContent = llmText;
                }
            }
            messages.push({ role: 'assistant', content: llmText });
        } catch (e) {
            llmDiv.textContent = '[Error: ' + e.message + ']';
        }
        sendBtn.disabled = false;
    }
    sendBtn.onclick = sendMessage;
    chatInput.addEventListener('keydown', function(e) {
        if (e.key === 'Enter') sendMessage();
    });

    // Register & Install Model logic
    const registerForm = document.getElementById('register-model-form');
    const registerStatus = document.getElementById('register-model-status');
    if (registerForm) {
      registerForm.onsubmit = async function(e) {
        e.preventDefault();
        registerStatus.textContent = '';
        let name = document.getElementById('register-model-name').value.trim();
        // Always prepend 'user.' if not already present
        if (!name.startsWith('user.')) {
          name = 'user.' + name;
        }
        const checkpoint = document.getElementById('register-checkpoint').value.trim();
        const recipe = document.getElementById('register-recipe').value;
        const reasoning = document.getElementById('register-reasoning').checked;
        const mmproj = document.getElementById('register-mmproj').value.trim();
        if (!name || !recipe) { return; }
        const payload = { model_name: name, recipe, reasoning };
        if (checkpoint) payload.checkpoint = checkpoint;
        if (mmproj) payload.mmproj = mmproj;
        const btn = document.getElementById('register-submit');
        btn.disabled = true;
        btn.textContent = 'Installing...';
        try {
          const resp = await fetch(getServerBaseUrl() + '/api/v1/pull', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
          });
          if (!resp.ok) {
            const err = await resp.json().catch(() => ({}));
            throw new Error(err.detail || 'Failed to register model.');          }
          registerStatus.textContent = 'Model installed!';
          registerStatus.style.color = '#27ae60';
          registerStatus.className = 'register-status success';
          registerForm.reset();
          await refreshModelMgmtUI();
          await loadModels(); // update chat dropdown too
        } catch (e) {
          registerStatus.textContent = e.message + ' See the Lemonade Server log for details.';
          registerStatus.style.color = '#dc3545';
          registerStatus.className = 'register-status error';
        }
        btn.disabled = false;
        btn.textContent = 'Install';
        refreshModelMgmtUI();
      };
    }
    </script>
</body>
</html>
